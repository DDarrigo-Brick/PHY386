{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2ZHhogwVT8wQTfUj7xrTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubsuny/PHY386/blob/main/2025/HW/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW5: Star Classification Using Machine Learning\n",
        "\n",
        "How to use an autoencoder and clustering to classify stars based on brightness.\n",
        "\n",
        "## Learning Outcomes\n",
        "By the end of this homework, you will:\n",
        "- Understand how to enable **GPU acceleration** in Google Colab for deep learning tasks.\n",
        "- Learn the fundamentals of **Machine Learning (ML)** and its applications in astrophysics.\n",
        "- Use **autoencoders** to extract compressed features from star images.\n",
        "- Apply **KMeans clustering** to classify stars based on brightness and size.\n",
        "- Visualize results with **matplotlib**."
      ],
      "metadata": {
        "id": "6aX4ESqPLReM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Enabling GPU Acceleration & Introduction to Machine Learning\n",
        "\n",
        "### How to Enable GPU Acceleration in Google Colab\n",
        "To train deep learning models efficiently, we need GPU acceleration:\n",
        "1. Go to **Runtime** in the top menu.\n",
        "2. Click **Change runtime type**.\n",
        "3. Set **Hardware Accelerator** to **GPU**.\n",
        "4. Click **Save**.\n",
        "\n",
        "To verify GPU availability, run the following command:"
      ],
      "metadata": {
        "id": "Yo5e5jmOn-cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "4QRLeNPMoB-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Machine Learning (ML)\n",
        "Machine Learning is a field of Artificial Intelligence (AI) that enables computers to learn patterns from data without being explicitly programmed. It is widely used in astronomy to classify celestial objects, detect anomalies, and analyze vast datasets.\n",
        "\n",
        "#### Types of Machine Learning:\n",
        "1. **Supervised Learning**: The model learns from labeled data (e.g., star classification with known brightness categories).\n",
        "2. **Unsupervised Learning**: The model finds patterns without predefined labels (e.g., clustering stars based on observed properties).\n",
        "3. **Reinforcement Learning**: The model learns by interacting with an environment and receiving rewards.\n",
        "\n",
        "In this notebook, we will use **unsupervised learning** with an **autoencoder** and **KMeans clustering**.\n",
        "\n",
        "### What is an Autoencoder?\n",
        "An autoencoder is a type of neural network used for unsupervised learning. It consists of:\n",
        "- **Encoder**: Compresses input data into a lower-dimensional representation.\n",
        "- **Bottleneck Layer**: The smallest representation of the data.\n",
        "- **Decoder**: Reconstructs the original input from the compressed representation.\n",
        "\n",
        "Autoencoders help in **dimensionality reduction** and **feature extraction** by learning compact representations of complex data.\n"
      ],
      "metadata": {
        "id": "uB1-WmPtoJ0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Required Libraries"
      ],
      "metadata": {
        "id": "1tVHUIQ9LUBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astropy scikit-learn tensorflow matplotlib numpy photutils auto-stretch"
      ],
      "metadata": {
        "id": "k8Ggf9ZFLZlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and Stretch the RGB FITS Image\n",
        "We first load astronomic pictures ([FITS file format](https://en.wikipedia.org/wiki/FITS?wprov=sfti1#)) and apply a **stretching function** (logarithmic/asinh) to enhance visibility. The general problem is that in general Astrononomic pictures are stored using 32-bit integer, while your display is only able to show 8-bot integer color range. So we have to tell the computer what to do with the missing colors.\n",
        "\n",
        "**ToDo**: Load and plot your assiged fits file (4 points)"
      ],
      "metadata": {
        "id": "Qh_0ixlvLepf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from astropy.io import fits\n",
        "from astropy.stats import sigma_clipped_stats\n",
        "from photutils.detection import DAOStarFinder\n",
        "from auto_stretch import apply_stretch\n",
        "from sklearn.cluster import KMeans\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Replace this URL with the raw URL of your FITS file on GitHub\n",
        "fits_url = \"\"\n",
        "\n",
        "# Fetch the FITS file from the GitHub repository\n",
        "response = requests.get(fits_url)\n",
        "response.raise_for_status()  # Check for request errors\n",
        "\n",
        "# Load the FITS file into an HDUList using BytesIO\n",
        "hdul = fits.open(BytesIO(response.content))\n",
        "\n",
        "# Assume the first extension contains an RGB image in (3, Height, Width) format\n",
        "rgb_data = np.transpose(hdul[0].data, (1, 2, 0))  # Shape should be (3, Height, Width)\n",
        "hdul.close() #\n",
        "\n",
        "# Display the image\n",
        "fig = plt.figure()\n",
        "plt.imshow(apply_stretch(rgb_data))"
      ],
      "metadata": {
        "id": "0xLqTFd_LmIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Count Stars Using Astropy\n",
        "We use **DAOStarFinder** to detect and count stars.\n",
        "\n",
        "**ToDo**: Extract the RGB channels seperately (4 points) and find an algorithm that makes the number of the detected stars in each channel the same (4 points). Plot the combined and the three RGB channels in a 2x2 grid plot highlighting the detecting stars.(4 points)\n",
        "\n",
        "Depending on your fits file you might have to select a part of the image for star detection."
      ],
      "metadata": {
        "id": "izAzEKTkNMKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the mean of the RGB channels\n",
        "avg_channel = np.mean(rgb_data[:, :, :], axis=2)\n",
        "\n",
        "def detect_stars(channel_data):\n",
        "    mean, median, std = sigma_clipped_stats(channel_data, sigma=3.0)\n",
        "    finder = DAOStarFinder(fwhm=3.0, threshold=5.0*std)\n",
        "    return finder(channel_data - median)\n",
        "\n",
        "# Detect stars\n",
        "sources = detect_stars(avg_channel)\n",
        "print(f\"Number of detected stars: {len(sources)}\")"
      ],
      "metadata": {
        "id": "AlCnTtCYliM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot detected stars\n",
        "plt.imshow(avg_channel, cmap='gray', origin='lower')\n",
        "plt.scatter(sources['xcentroid'], sources['ycentroid'], s=30, edgecolor='red', facecolors='none')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JtA_s2uDNPqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Feature Extraction\n",
        "\n",
        "**Stellar Colors and Surface Temperatures**  \n",
        "Stars exhibit a variety of colors primarily because of their differing **surface temperatures**. The color of a star is directly related to its temperature: hotter stars emit more blue and ultraviolet light, while cooler stars emit more red and infrared light. This temperature dependence is explained by the concept of **blackbody radiation** and is captured in the [Planck's law](https://en.wikipedia.org/wiki/Planck%27s_law) of radiation. The [spectral classification](https://en.wikipedia.org/wiki/Stellar_classification) system categorizes stars into types (O, B, A, F, G, K, M) based on these temperatures, where O-type stars are extremely hot and blue, and M-type stars are cool and red. Understanding these differences helps astronomers not only determine the physical properties of stars but also track their evolutionary stages.\n",
        "\n",
        "**Luminosity, Brightness, and the Hertzsprung–Russell Diagram**  \n",
        "The apparent brightness of a star as seen from Earth is influenced by its intrinsic **luminosity** and its distance from the observer. Luminosity, the total energy output of a star per unit time, varies dramatically depending on the star’s mass, age, and evolutionary stage. This relationship is visualized in the [Hertzsprung–Russell diagram](https://en.wikipedia.org/wiki/Hertzsprung%E2%80%93Russell_diagram), which plots stars according to their luminosity and surface temperature. In this diagram, stars with higher luminosities can be found on the upper regions regardless of their color, indicating that a star's brightness is not solely a function of its temperature but also of its size and the stage of its [stellar evolution](https://en.wikipedia.org/wiki/Stellar_evolution). Such insights allow astronomers to predict the future behavior of stars and understand the underlying physics governing their life cycles.\n",
        "\n",
        "**Composition, Metallicity, and Evolutionary Effects**  \n",
        "Beyond temperature and mass, a star's **composition** plays a critical role in determining both its color and brightness. The abundance of elements heavier than helium—referred to as [metallicity](https://en.wikipedia.org/wiki/Metallicity)—can affect the opacity of a star's outer layers, influencing how energy is transported to the surface and thus its color and luminosity. Additionally, stars evolve over time; for example, stars in the later stages of [stellar evolution](https://en.wikipedia.org/wiki/Stellar_evolution) can swell into red giants, drastically changing their brightness and color profiles. This evolutionary process, combined with variations in initial mass and metallicity, leads to a rich diversity in the observed properties of stars. Together, these factors help astronomers piece together the history of our galaxy and the lifecycle of its stellar populations.\n",
        "\n",
        "\n",
        "We extract:\n",
        "- **Brightness (flux)** from each RGB channel.\n",
        "- **Color Ratios**: R/G and B/G ratios to capture color differences.\n",
        "- **Size Proxy** from sharpness values.\n",
        "We normalize the extracted features for efficient learning.\n",
        "\n",
        "**ToDo**: calculate the color ratios (4 points) and normalized flux ratios (4 points) for each color channel (R/G and B/G) for further analysis and generate a new `features` variable (4 points).\n",
        "\n",
        "If you have very bright stars in your fits file you might have to use the `remove_extreme_brightness` function."
      ],
      "metadata": {
        "id": "nLOi3z5NyfAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features (brightness and size)\n",
        "flux = sources['flux']\n",
        "\n",
        "# Compute size proxy\n",
        "size = sources['sharpness']\n",
        "\n",
        "# Normalize features\n",
        "flux_norm = (flux - np.min(flux)) / (np.max(flux) - np.min(flux))\n",
        "size_norm = (size - np.min(size)) / (np.max(size) - np.min(size))\n",
        "\n",
        "features = np.vstack([flux_norm, size_norm]).T"
      ],
      "metadata": {
        "id": "KqXxX2EbyeLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_extreme_brightness(star_features, brightness_threshold=3.0):\n",
        "    \"\"\"\n",
        "    Filters out stars with exceptionally high brightness from a dataset of star features.\n",
        "\n",
        "    This function calculates the overall brightness of each star by computing the Euclidean norm\n",
        "    of its feature vector. It then determines the mean and standard deviation of these brightness\n",
        "    values. Stars whose brightness exceeds the mean by more than a specified number of standard\n",
        "    deviations (defined by `brightness_threshold`) are considered outliers and removed from the dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    star_features : ndarray\n",
        "        A 2D NumPy array of shape (n_stars, n_features), where each row represents the feature vector\n",
        "        of a star. It is assumed that the features are numerical and relevant to the brightness calculation.\n",
        "    brightness_threshold : float, optional\n",
        "        The number of standard deviations above the mean brightness to use as the cutoff for identifying\n",
        "        extreme brightness values. The default is 3.0, which corresponds to the common statistical practice\n",
        "        of removing data points that lie more than three standard deviations from the mean.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    filtered_star_features : ndarray\n",
        "        A 2D NumPy array containing the feature vectors of stars that are not considered extreme in brightness.\n",
        "    filtered_indices : ndarray\n",
        "        A 1D boolean NumPy array indicating which stars were retained (True) and which were filtered out (False).\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - The function assumes that the Euclidean norm of the feature vectors is an appropriate measure of\n",
        "      brightness. Ensure that the input features are scaled or selected accordingly.\n",
        "    - This method uses a statistical approach to identify outliers based on the assumption of a normal\n",
        "      distribution of brightness values. If the brightness distribution is significantly non-normal,\n",
        "      consider using alternative outlier detection methods.\n",
        "    - The function utilizes NumPy's `linalg.norm` to compute the Euclidean norm and `mean` and `std`\n",
        "      functions to calculate statistical measures.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import numpy as np\n",
        "    >>> star_features = np.array([[1.0, 2.0], [2.0, 2.0], [10.0, 10.0]])\n",
        "    >>> filtered_features, filtered_indices = remove_extreme_brightness(star_features)\n",
        "    >>> filtered_features\n",
        "    array([[1., 2.],\n",
        "           [2., 2.]])\n",
        "    >>> filtered_indices\n",
        "    array([ True,  True, False])\n",
        "    \"\"\"\n",
        "\n",
        "    brightness = np.linalg.norm(star_features, axis=1)  # Compute overall brightness\n",
        "    mean_brightness = np.mean(brightness)\n",
        "    std_brightness = np.std(brightness)\n",
        "    filtered_indices = brightness < (mean_brightness + brightness_threshold * std_brightness)\n",
        "    return star_features[filtered_indices], filtered_indices"
      ],
      "metadata": {
        "id": "X_9CfVazZPTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Autoencoder for Feature Compression\n",
        "An **autoencoder** is a neural network used for unsupervised learning. It learns a compact representation of input data.\n",
        "\n",
        "### Network Architecture:\n",
        "- **Input Layer**: Takes in two features (brightness and size).\n",
        "- **Encoder**:\n",
        "  - A hidden layer with 8 neurons extracts patterns.\n",
        "  - A bottleneck layer with 2 neurons compresses the data.\n",
        "- **Decoder**:\n",
        "  - Expands data back to 8 neurons.\n",
        "  - Outputs the reconstructed 2-feature data.\n",
        "\n",
        "**ToDo**: Adapt the input and output shape to the new feature generated above (4 points) and use the GPU for acceleration (2 points)."
      ],
      "metadata": {
        "id": "cQs8e4Fmy5WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an autoencoder model\n",
        "input_layer = Input(shape=(2,))\n",
        "encoded = Dense(8, activation='relu')(input_layer)\n",
        "encoded = Dense(2, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(8, activation='relu')(encoded)\n",
        "decoded = Dense(2, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train autoencoder\n",
        "autoencoder.fit(features, features, epochs=50, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "id": "vSn0JANyOLq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Clustering with KMeans\n",
        "After extracting compressed features, we use **KMeans clustering** to classify the stars."
      ],
      "metadata": {
        "id": "zJgiprAIzEAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_layer, encoded)\n",
        "encoded_features = encoder.predict(features)\n",
        "\n",
        "num_clusters = 4\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "predicted_labels = kmeans.fit_predict(encoded_features)"
      ],
      "metadata": {
        "id": "mD4fEWOry_nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6a: Generating Synthetic Star Data\n",
        "To demonstrate clustering in astrophysics, we generate synthetic stars with controlled properties.\n",
        "This helps visualize how clustering can be applied to real astrophysical problems, such as distinguishing star populations.\n"
      ],
      "metadata": {
        "id": "H31jpUqV3UFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_synthetic_stars(num_stars=300):\n",
        "    \"\"\"Generates synthetic star data with predefined color and brightness properties.\"\"\"\n",
        "    categories = {\n",
        "        0: {'rg': 0.9, 'bg': 0.5, 'scatter': 0.1},  # Red stars\n",
        "        1: {'rg': 0.5, 'bg': 0.9, 'scatter': 0.1},  # Blue stars\n",
        "        2: {'rg': 0.7, 'bg': 0.7, 'scatter': 0.05}, # White stars\n",
        "        3: {'rg': 0.2, 'bg': 0.3, 'scatter': 0.1},  # Dim stars\n",
        "    }\n",
        "\n",
        "    stars = []\n",
        "    labels = []\n",
        "\n",
        "    for _ in range(num_stars):\n",
        "        category = random.choice(list(categories.keys()))\n",
        "        base = categories[category]\n",
        "        rg = max(0, min(1, np.random.normal(base['rg'], base['scatter'])))\n",
        "        bg = max(0, min(1, np.random.normal(base['bg'], base['scatter'])))\n",
        "        stars.append([rg, bg])\n",
        "        labels.append(category)\n",
        "\n",
        "    return np.array(stars), np.array(labels)\n",
        "\n",
        "# Generate and plot synthetic stars\n",
        "synthetic_stars, synthetic_labels = generate_synthetic_stars()\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(synthetic_stars[:,0], synthetic_stars[:,1], c=synthetic_labels, cmap='coolwarm', alpha=0.7, edgecolors='k')\n",
        "plt.xlabel('Synthetic R/G Ratio')\n",
        "plt.ylabel('Synthetic B/G Ratio')\n",
        "plt.colorbar(label='Simulated Star Category')\n",
        "plt.title('Synthetic Star Classification Example')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wDA1YtF124_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6b: Visualizing real data\n",
        "We plot stars with different colors representing their assigned clusters.\n",
        "\n",
        "Clusters represent groups of stars with similar size and brightness. If clusters overlap too much, it might indicate the need for better feature separation.\n",
        "\n",
        "**ToDo**: Generate new plots from the new clustering for the cololr ratio and size/brightness (8 points)\n",
        "- **X-axis: Normalized R/G Ratio** – Represents how red the star is relative to green.\n",
        "- **Y-axis: Normalized B/G Ratio** – Represents how blue the star is relative to green.\n",
        "- **Point Color: Cluster Label** – Assigned cluster based on autoencoder features and KMeans."
      ],
      "metadata": {
        "id": "68wG2xFXzP40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(flux_norm, size_norm, c=predicted_labels, cmap='viridis', alpha=0.7, edgecolors='k')\n",
        "plt.xlabel('Normalized flux')\n",
        "plt.ylabel('Normalized size')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.title('Star Classification by Size & Brightness')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zYghX_7AzIeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Refining the Clustering\n",
        "To improve clustering, we:\n",
        "1. **Increase Number of Clusters** – To separate stars into more detailed groups.\n",
        "2. **Use Gaussian Mixture Model (GMM)** – A probabilistic alternative to KMeans for soft clustering."
      ],
      "metadata": {
        "id": "D1goRLpN26Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Try different numbers of clusters\n",
        "num_clusters_gmm = 6\n",
        "gmm = GaussianMixture(n_components=num_clusters_gmm, random_state=42)\n",
        "predicted_labels_gmm = gmm.fit_predict(encoded_features)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(flux_norm, size_norm, c=predicted_labels_gmm, cmap='plasma', alpha=0.7, edgecolors='k')\n",
        "plt.xlabel('Normalized brightness')\n",
        "plt.ylabel('Normalized size')\n",
        "plt.colorbar(label='GMM Cluster')\n",
        "plt.title('Refined Star Classification with Gaussian Mixture Model')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P3dSIEl8zTXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79Rs49Bt3ZiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}